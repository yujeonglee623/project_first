import streamlit as st
import pandas as pd
import re
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import numpy as np
from wordcloud import WordCloud

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Reddit íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
<style>
    .main > div {
        padding-top: 2rem;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
    }
</style>
""", unsafe_allow_html=True)

# ============================================
# í•¨ìˆ˜ ì •ì˜
# ============================================

@st.cache_data
def load_data(file):
    """ë°ì´í„° ë¡œë“œ"""
    df = pd.read_csv(file)
    return df

def clean_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    if pd.isna(text):
        return ""
    text = str(text).lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'[^\w\s]', ' ', text)
    return text

def extract_words(text, min_length=3):
    """ë‹¨ì–´ ì¶”ì¶œ"""
    stopwords = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',
        'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
        'could', 'should', 'may', 'might', 'can', 'my', 'your', 'their',
        'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it',
        'we', 'they', 'me', 'him', 'her', 'us', 'them', 'what', 'which',
        'who', 'when', 'where', 'why', 'how', 'all', 'each', 'every',
        'both', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'not',
        'only', 'own', 'same', 'so', 'than', 'too', 'very', 'just', 'really',
        'also', 'like', 'get', 'got', 'use', 'used', 'using', 'one', 'two'
    }
    
    words = clean_text(text).split()
    return [w for w in words if len(w) >= min_length and w not in stopwords]

# ============================================
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# ============================================

st.title("ğŸ“Š Reddit íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.markdown("---")

# ì‚¬ì´ë“œë°” - íŒŒì¼ ì—…ë¡œë“œ ë° ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    uploaded_file = st.file_uploader(
        "ëŒ“ê¸€ ë¶„ì„ CSV íŒŒì¼ ì—…ë¡œë“œ",
        type=['csv'],
        help="comment_analysis.csv íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    st.markdown("---")
    
    if uploaded_file:
        st.success("âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ!")
        df = load_data(uploaded_file)
        st.metric("ì´ ëŒ“ê¸€ ìˆ˜", f"{len(df):,}ê°œ")
        
        if 'sentiment' in df.columns:
            positive = len(df[df['sentiment'] == 'POSITIVE'])
            negative = len(df[df['sentiment'] == 'NEGATIVE'])
            st.metric("ê¸ì • ë¹„ìœ¨", f"{positive/len(df)*100:.1f}%")
            st.metric("ë¶€ì • ë¹„ìœ¨", f"{negative/len(df)*100:.1f}%")
    
    st.markdown("---")
    st.markdown("### ğŸ“– ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. CSV íŒŒì¼ ì—…ë¡œë“œ
    2. ì›í•˜ëŠ” ë¶„ì„ íƒ­ ì„ íƒ
    3. ì„¤ì • ì¡°ì • í›„ ë¶„ì„ ì‹¤í–‰
    """)

# íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
if not uploaded_file:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ",
    "ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„",
    "ğŸ˜ŠğŸ˜ ê°ì„± í‚¤ì›Œë“œ",
    "ğŸ“ˆ ì‹œê°„ íŠ¸ë Œë“œ",
    "ğŸ”— í‚¤ì›Œë“œ ì—°ê´€",
    "ğŸ·ï¸ í† í”½ ë¹„êµ"
])

# ============================================
# íƒ­ 1: ì›Œë“œí´ë¼ìš°ë“œ
# ============================================
with tab1:
    st.header("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„")
    st.markdown("ëŒ“ê¸€ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("ì„¤ì •")
        min_word_length = st.slider("ìµœì†Œ ë‹¨ì–´ ê¸¸ì´", 2, 5, 3)
        top_n_words = st.slider("í‘œì‹œí•  ë‹¨ì–´ ìˆ˜", 20, 100, 50)
        
        if st.button("ğŸ¨ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±", key="wc_btn"):
            with st.spinner("ìƒì„± ì¤‘..."):
                # ëª¨ë“  ëŒ“ê¸€ í•©ì¹˜ê¸°
                all_text = ' '.join(df['comment_body'].apply(clean_text))
                words = extract_words(all_text, min_word_length)
                word_freq = Counter(words)
                
                # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
                wordcloud = WordCloud(
                    width=1200,
                    height=600,
                    background_color='white',
                    colormap='viridis',
                    relative_scaling=0.5,
                    min_font_size=10
                ).generate_from_frequencies(dict(word_freq.most_common(top_n_words)))
                
                # ì‹œê°í™”
                fig, ax = plt.subplots(figsize=(15, 8))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                
                with col2:
                    st.pyplot(fig)
                
                # ìƒìœ„ ë‹¨ì–´ í…Œì´ë¸”
                st.subheader("ğŸ“‹ ìƒìœ„ í‚¤ì›Œë“œ")
                top_words_df = pd.DataFrame(
                    word_freq.most_common(20),
                    columns=['ë‹¨ì–´', 'ë¹ˆë„']
                )
                st.dataframe(top_words_df, use_container_width=True)
    
    with col2:
        if 'wordcloud' not in locals():
            st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ 'ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# ============================================
# íƒ­ 2: í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
# ============================================
with tab2:
    st.header("ğŸ“Š í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„")
    st.markdown("íŠ¹ì • í‚¤ì›Œë“œë“¤ì˜ ì–¸ê¸‰ ë¹ˆë„ì™€ ê°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # í‚¤ì›Œë“œ ì…ë ¥
    st.subheader("ğŸ” ë¶„ì„í•  í‚¤ì›Œë“œ ì…ë ¥")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        keywords_input = st.text_area(
            "í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            value="toner, serum, cream, cleanser, mask, sunscreen, niacinamide, retinol, vitamin c, hyaluronic acid",
            height=100,
            help="ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì…ë ¥í•˜ì„¸ìš”"
        )
    
    with col2:
        top_n = st.number_input("í‘œì‹œí•  ìƒìœ„ ê°œìˆ˜", 5, 30, 15)
        show_sentiment = st.checkbox("ê°ì„± ë¶„ì„ í¬í•¨", value=True)
    
    if st.button("ğŸ“Š ë¶„ì„ ì‹œì‘", key="kf_btn"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            custom_keywords = [kw.strip().lower() for kw in keywords_input.split(',')]
            
            keyword_stats = []
            has_sentiment = 'sentiment' in df.columns
            
            for keyword in custom_keywords:
                total_count = 0
                positive_count = 0
                negative_count = 0
                total_score = 0
                
                for idx, row in df.iterrows():
                    text = row['comment_body']
                    if pd.notna(text) and keyword.lower() in str(text).lower():
                        total_count += 1
                        total_score += row.get('comment_score', 0)
                        
                        if has_sentiment and show_sentiment:
                            if row['sentiment'] == 'POSITIVE':
                                positive_count += 1
                            elif row['sentiment'] == 'NEGATIVE':
                                negative_count += 1
                
                keyword_stats.append({
                    'keyword': keyword,
                    'count': total_count,
                    'percentage': round(total_count / len(df) * 100, 2),
                    'positive': positive_count,
                    'negative': negative_count,
                    'positive_rate': round(positive_count / total_count * 100, 1) if total_count > 0 else 0,
                    'negative_rate': round(negative_count / total_count * 100, 1) if total_count > 0 else 0,
                    'avg_score': round(total_score / total_count, 2) if total_count > 0 else 0
                })
            
            result_df = pd.DataFrame(keyword_stats)
            result_df = result_df.sort_values('count', ascending=False).head(top_n)
            
            # ê·¸ë˜í”„
            if has_sentiment and show_sentiment:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ì–¸ê¸‰ ë¹ˆë„")
                    fig1, ax1 = plt.subplots(figsize=(10, 8))
                    ax1.barh(result_df['keyword'], result_df['count'], color='steelblue')
                    ax1.set_xlabel('Mentions')
                    ax1.invert_yaxis()
                    st.pyplot(fig1)
                
                with col2:
                    st.subheader("ê°ì„± ë¹„ìœ¨")
                    fig2, ax2 = plt.subplots(figsize=(10, 8))
                    y_pos = range(len(result_df))
                    ax2.barh(y_pos, result_df['positive_rate'], color='lightgreen', label='Positive')
                    ax2.barh(y_pos, result_df['negative_rate'], left=result_df['positive_rate'], 
                            color='lightcoral', label='Negative')
                    ax2.set_yticks(y_pos)
                    ax2.set_yticklabels(result_df['keyword'])
                    ax2.set_xlabel('Sentiment Rate (%)')
                    ax2.set_xlim(0, 100)
                    ax2.legend()
                    ax2.invert_yaxis()
                    st.pyplot(fig2)
            else:
                fig, ax = plt.subplots(figsize=(12, 8))
                ax.barh(result_df['keyword'], result_df['count'], color='skyblue')
                ax.set_xlabel('Mentions')
                ax.invert_yaxis()
                st.pyplot(fig)
            
            # í…Œì´ë¸”
            st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„°")
            if has_sentiment and show_sentiment:
                display_df = result_df[['keyword', 'count', 'percentage', 'positive_rate', 'negative_rate', 'avg_score']]
                display_df.columns = ['í‚¤ì›Œë“œ', 'ì–¸ê¸‰ìˆ˜', 'ë¹„ìœ¨(%)', 'ê¸ì •ë¥ (%)', 'ë¶€ì •ë¥ (%)', 'í‰ê· ì ìˆ˜']
            else:
                display_df = result_df[['keyword', 'count', 'percentage']]
                display_df.columns = ['í‚¤ì›Œë“œ', 'ì–¸ê¸‰ìˆ˜', 'ë¹„ìœ¨(%)']
            
            st.dataframe(display_df, use_container_width=True)
            
            # ë‹¤ìš´ë¡œë“œ
            csv = result_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                csv,
                "keyword_frequency.csv",
                "text/csv"
            )

# ============================================
# íƒ­ 3: ê°ì„±ë³„ í‚¤ì›Œë“œ
# ============================================
with tab3:
    st.header("ğŸ˜ŠğŸ˜ ê°ì„±ë³„ í‚¤ì›Œë“œ ë¶„ì„")
    st.markdown("ê¸ì • ëŒ“ê¸€ê³¼ ë¶€ì • ëŒ“ê¸€ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
    
    if 'sentiment' not in df.columns:
        st.warning("âš ï¸ ê°ì„± ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col1, col2 = st.columns([1, 3])
        
        with col1:
            st.subheader("ì„¤ì •")
            top_n_sentiment = st.slider("í‘œì‹œí•  í‚¤ì›Œë“œ ìˆ˜", 10, 30, 15, key="sent_slider")
            min_length = st.slider("ìµœì†Œ ë‹¨ì–´ ê¸¸ì´", 2, 5, 3, key="sent_length")
            
            if st.button("ğŸ” ë¶„ì„ ì‹œì‘", key="sent_btn"):
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    positive_comments = df[df['sentiment'] == 'POSITIVE']['comment_body']
                    negative_comments = df[df['sentiment'] == 'NEGATIVE']['comment_body']
                    
                    # ê¸ì • í‚¤ì›Œë“œ
                    positive_text = ' '.join(positive_comments.apply(clean_text))
                    positive_words = extract_words(positive_text, min_length)
                    positive_freq = Counter(positive_words).most_common(top_n_sentiment)
                    
                    # ë¶€ì • í‚¤ì›Œë“œ
                    negative_text = ' '.join(negative_comments.apply(clean_text))
                    negative_words = extract_words(negative_text, min_length)
                    negative_freq = Counter(negative_words).most_common(top_n_sentiment)
                    
                    # ê·¸ë˜í”„
                    with col2:
                        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
                        
                        # ê¸ì •
                        pos_words = [w for w, c in positive_freq]
                        pos_counts = [c for w, c in positive_freq]
                        ax1.barh(pos_words, pos_counts, color='lightgreen')
                        ax1.set_xlabel('Frequency')
                        ax1.set_title('ğŸ˜Š Positive Keywords', color='green', fontsize=14)
                        ax1.invert_yaxis()
                        
                        # ë¶€ì •
                        neg_words = [w for w, c in negative_freq]
                        neg_counts = [c for w, c in negative_freq]
                        ax2.barh(neg_words, neg_counts, color='lightcoral')
                        ax2.set_xlabel('Frequency')
                        ax2.set_title('ğŸ˜ Negative Keywords', color='red', fontsize=14)
                        ax2.invert_yaxis()
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                    
                    # í…Œì´ë¸”
                    st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„°")
                    col_a, col_b = st.columns(2)
                    
                    with col_a:
                        st.markdown("**ğŸ˜Š ê¸ì • í‚¤ì›Œë“œ**")
                        pos_df = pd.DataFrame(positive_freq, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
                        st.dataframe(pos_df, use_container_width=True)
                    
                    with col_b:
                        st.markdown("**ğŸ˜ ë¶€ì • í‚¤ì›Œë“œ**")
                        neg_df = pd.DataFrame(negative_freq, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
                        st.dataframe(neg_df, use_container_width=True)
        
        with col2:
            if 'positive_freq' not in locals():
                st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# ============================================
# íƒ­ 4: ì‹œê°„ íŠ¸ë Œë“œ
# ============================================
with tab4:
    st.header("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ í‚¤ì›Œë“œ íŠ¸ë Œë“œ")
    st.markdown("ì‹œê°„ì— ë”°ë¥¸ í‚¤ì›Œë“œ ì–¸ê¸‰ëŸ‰ ë³€í™”ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.")
    
    if 'comment_created' not in df.columns:
        st.warning("âš ï¸ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.subheader("ğŸ” ë¶„ì„í•  í‚¤ì›Œë“œ ì„ íƒ")
        
        trend_keywords = st.text_input(
            "í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            value="hydrating, brightening, anti-aging",
            help="ìµœëŒ€ 5ê°œê¹Œì§€ ì¶”ì²œ"
        )
        
        if st.button("ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„", key="trend_btn"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                df['date'] = pd.to_datetime(df['comment_created']).dt.date
                keywords = [kw.strip().lower() for kw in trend_keywords.split(',')][:5]
                
                trend_data = []
                for keyword in keywords:
                    for date in df['date'].unique():
                        date_comments = df[df['date'] == date]['comment_body']
                        count = sum(1 for text in date_comments if pd.notna(text) and keyword in str(text).lower())
                        trend_data.append({
                            'date': date,
                            'keyword': keyword,
                            'count': count
                        })
                
                trend_df = pd.DataFrame(trend_data)
                
                # ê·¸ë˜í”„
                fig, ax = plt.subplots(figsize=(14, 8))
                for keyword in keywords:
                    keyword_data = trend_df[trend_df['keyword'] == keyword]
                    ax.plot(keyword_data['date'], keyword_data['count'], 
                           marker='o', label=keyword, linewidth=2)
                
                ax.set_xlabel('Date', fontsize=12)
                ax.set_ylabel('Mentions', fontsize=12)
                ax.set_title('Keyword Trends Over Time', fontsize=16)
                ax.legend(fontsize=10)
                ax.grid(True, alpha=0.3)
                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)
                
                # í…Œì´ë¸”
                st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„°")
                pivot_df = trend_df.pivot(index='date', columns='keyword', values='count')
                st.dataframe(pivot_df, use_container_width=True)

# ============================================
# íƒ­ 5: í‚¤ì›Œë“œ ê³µì¶œí˜„
# ============================================
with tab5:
    st.header("ğŸ”— í‚¤ì›Œë“œ ê³µì¶œí˜„ ë¶„ì„")
    st.markdown("í•¨ê»˜ ì–¸ê¸‰ë˜ëŠ” í‚¤ì›Œë“œë“¤ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.subheader("ì„¤ì •")
        top_words_co = st.slider("ë¶„ì„í•  ìƒìœ„ í‚¤ì›Œë“œ ìˆ˜", 10, 40, 20, key="co_slider")
        
        if st.button("ğŸ”— ë¶„ì„ ì‹œì‘", key="co_btn"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
                all_text = ' '.join(df['comment_body'].apply(clean_text))
                words = extract_words(all_text, 3)
                top_words = [w for w, c in Counter(words).most_common(top_words_co)]
                
                # ê³µì¶œí˜„ ë§¤íŠ¸ë¦­ìŠ¤
                cooccurrence = np.zeros((len(top_words), len(top_words)))
                
                for text in df['comment_body']:
                    if pd.isna(text):
                        continue
                    comment_words = set(extract_words(str(text), 3))
                    for i, word1 in enumerate(top_words):
                        for j, word2 in enumerate(top_words):
                            if word1 in comment_words and word2 in comment_words:
                                cooccurrence[i][j] += 1
                
                # íˆíŠ¸ë§µ
                with col2:
                    fig, ax = plt.subplots(figsize=(14, 12))
                    sns.heatmap(cooccurrence, xticklabels=top_words, yticklabels=top_words,
                               cmap='YlOrRd', annot=False, fmt='g', cbar_kws={'label': 'Co-occurrence Count'})
                    plt.xticks(rotation=45, ha='right')
                    plt.yticks(rotation=0)
                    plt.tight_layout()
                    st.pyplot(fig)
                
                # ìƒìœ„ ì¡°í•©
                st.subheader("ğŸ”¥ ê°€ì¥ ë§ì´ í•¨ê»˜ ì–¸ê¸‰ë˜ëŠ” í‚¤ì›Œë“œ ì¡°í•©")
                pairs = []
                for i in range(len(top_words)):
                    for j in range(i+1, len(top_words)):
                        if cooccurrence[i][j] > 0:
                            pairs.append((top_words[i], top_words[j], int(cooccurrence[i][j])))
                
                pairs.sort(key=lambda x: x[2], reverse=True)
                pairs_df = pd.DataFrame(pairs[:15], columns=['í‚¤ì›Œë“œ 1', 'í‚¤ì›Œë“œ 2', 'ê³µì¶œí˜„ íšŸìˆ˜'])
                st.dataframe(pairs_df, use_container_width=True)
    
    with col2:
        if 'cooccurrence' not in locals():
            st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# ============================================
# íƒ­ 6: í† í”½ ë¹„êµ
# ============================================
with tab6:
    st.header("ğŸ·ï¸ í† í”½ ê·¸ë£¹ ë¹„êµ")
    st.markdown("ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ í† í”½ë³„ ì¸ê¸°ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
    
    st.subheader("ğŸ¯ í† í”½ ê·¸ë£¹ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        topic1_name = st.text_input("í† í”½ 1 ì´ë¦„", "Hydration")
        topic1_keywords = st.text_input("í† í”½ 1 í‚¤ì›Œë“œ", "hydrating, moisture, dewy, plump")
        
        topic2_name = st.text_input("í† í”½ 2 ì´ë¦„", "Brightening")
        topic2_keywords = st.text_input("í† í”½ 2 í‚¤ì›Œë“œ", "brightening, glow, radiant, luminous")
    
    with col2:
        topic3_name = st.text_input("í† í”½ 3 ì´ë¦„", "Anti-Aging")
        topic3_keywords = st.text_input("í† í”½ 3 í‚¤ì›Œë“œ", "anti-aging, wrinkle, firm, lifting")
        
        topic4_name = st.text_input("í† í”½ 4 ì´ë¦„", "Acne")
        topic4_keywords = st.text_input("í† í”½ 4 í‚¤ì›Œë“œ", "acne, breakout, pimple, blemish")
    
    if st.button("ğŸ·ï¸ í† í”½ ë¹„êµ ë¶„ì„", key="topic_btn"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            topic_groups = {
                topic1_name: [k.strip().lower() for k in topic1_keywords.split(',')],
                topic2_name: [k.strip().lower() for k in topic2_keywords.split(',')],
                topic3_name: [k.strip().lower() for k in topic3_keywords.split(',')],
                topic4_name: [k.strip().lower() for k in topic4_keywords.split(',')]
            }
            
            topic_stats = []
            has_sentiment = 'sentiment' in df.columns
            
            for topic, keywords in topic_groups.items():
                mentions = 0
                positive = 0
                negative = 0
                total_score = 0
                
                for idx, row in df.iterrows():
                    text = str(row['comment_body']).lower()
                    if any(kw in text for kw in keywords):
                        mentions += 1
                        total_score += row.get('comment_score', 0)
                        
                        if has_sentiment:
                            if row['sentiment'] == 'POSITIVE':
                                positive += 1
                            elif row['sentiment'] == 'NEGATIVE':
                                negative += 1
                
                topic_stats.append({
                    'topic': topic,
                    'mentions': mentions,
                    'positive': positive,
                    'negative': negative,
                    'positive_rate': round(positive / mentions * 100, 1) if mentions > 0 else 0,
                    'avg_score': round(total_score / mentions, 2) if mentions > 0 else 0
                })
            
            result_df = pd.DataFrame(topic_stats)
            
            # ê·¸ë˜í”„
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ì–¸ê¸‰ ë¹ˆë„")
                fig1, ax1 = plt.subplots(figsize=(10, 6))
                ax1.bar(result_df['topic'], result_df['mentions'], color='steelblue')
                ax1.set_ylabel('Mentions')
                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig1)
            
            if has_sentiment:
                with col2:
                    st.subheader("ê¸ì •ë¥ ")
                    fig2, ax2 = plt.subplots(figsize=(10, 6))
                    ax2.bar(result_df['topic'], result_df['positive_rate'], color='lightgreen')
                    ax2.set_ylabel('Positive Rate (%)')
                    ax2.set_ylim(0, 100)
                    plt.xticks(rotation=45)
                    plt.tight_layout()
                    st.pyplot(fig2)
            
            # í…Œì´ë¸”
            st.subheader("ğŸ“‹ í† í”½ë³„ í†µê³„")
            display_df = result_df[['topic', 'mentions', 'positive_rate', 'avg_score']]
            display_df.columns = ['í† í”½', 'ì–¸ê¸‰ìˆ˜', 'ê¸ì •ë¥ (%)', 'í‰ê· ì ìˆ˜']
            st.dataframe(display_df, use_container_width=True)

# Footer
st.markdown("---")
st.markdown("Made with â¤ï¸ using Streamlit | Reddit Trend Analysis Dashboard")